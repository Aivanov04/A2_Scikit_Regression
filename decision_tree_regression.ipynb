{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Decision Tree Regression",
   "id": "ddce40c8a0922944"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-23T18:32:28.693977Z",
     "start_time": "2025-11-23T18:32:28.691114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from prettytable import PrettyTable"
   ],
   "id": "78bd4fa01722e6ff",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:32:28.705517Z",
     "start_time": "2025-11-23T18:32:28.700915Z"
    }
   },
   "cell_type": "code",
   "source": "steel_data = pd.read_csv(\"steel.csv\")",
   "id": "aae81b623124b895",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:32:28.711465Z",
     "start_time": "2025-11-23T18:32:28.708414Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Features of the dataset, all cols bar the last\n",
    "features = steel_data.values[:, :-1]\n",
    "# Ground truths, the last column\n",
    "ground_truths = steel_data.values[:, -1]\n",
    "\n",
    "kf = KFold(n_splits=10, shuffle=False)"
   ],
   "id": "ee708d36f9da253",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:32:28.903572Z",
     "start_time": "2025-11-23T18:32:28.717261Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = DecisionTreeRegressor(random_state=4)\n",
    "\n",
    "scores_headers = [\"Fold\", \"R2 Score\", \"Mean Squared Error\"]\n",
    "scores_list = []\n",
    "for i, (train_index, test_index) in enumerate(kf.split(features)):\n",
    "    # Features and ground truths for the ith fold\n",
    "    training_features, test_features = features[train_index], features[test_index]\n",
    "    training_ground_truths, test_ground_truths = ground_truths[train_index], ground_truths[test_index]\n",
    "\n",
    "    model.fit(training_features, training_ground_truths)\n",
    "\n",
    "    prediction = model.predict(test_features)\n",
    "\n",
    "    r2 = r2_score(test_ground_truths, prediction)\n",
    "    print(f\"R2 Score: {r2}\")\n",
    "\n",
    "    mse = mean_squared_error(test_ground_truths, prediction)\n",
    "    print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "    scores_list.append([f\"{i+1}\", f\"{r2:.2f}\", f\"{mse:.2f}\"])\n",
    "\n",
    "param_grid={\n",
    "    \"max_depth\" : [3,4,5,6,7,8],\n",
    "    \"min_samples_leaf\" : [3,4,5,6,7,8]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=kf, scoring=\"r2\", n_jobs=-1)\n",
    "\n",
    "grid_search.fit(features, ground_truths)\n",
    "\n",
    "print(grid_search.best_params_)"
   ],
   "id": "d4a7905f20e783fd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.44960274424132096\n",
      "Mean Squared Error: 2307.9395212180257\n",
      "R2 Score: -0.236365905073864\n",
      "Mean Squared Error: 5851.158630070643\n",
      "R2 Score: 0.5958985898959019\n",
      "Mean Squared Error: 2747.8411156805864\n",
      "R2 Score: 0.7377646274260763\n",
      "Mean Squared Error: 1587.7106136995649\n",
      "R2 Score: 0.6406829018426705\n",
      "Mean Squared Error: 1807.8740823017777\n",
      "R2 Score: 0.70372234387163\n",
      "Mean Squared Error: 2304.3123582998746\n",
      "R2 Score: 0.5017404975697688\n",
      "Mean Squared Error: 2074.9348088182965\n",
      "R2 Score: 0.38001865387776135\n",
      "Mean Squared Error: 3719.8592003374024\n",
      "R2 Score: 0.32652633099421635\n",
      "Mean Squared Error: 7637.251104851183\n",
      "R2 Score: 0.3270044819868978\n",
      "Mean Squared Error: 5687.030084735499\n",
      "{'max_depth': 7, 'min_samples_leaf': 6}\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-23T18:32:28.912694Z",
     "start_time": "2025-11-23T18:32:28.909277Z"
    }
   },
   "cell_type": "code",
   "source": [
    "table = PrettyTable()\n",
    "\n",
    "table.title = \"Error Scores with Default Params\"\n",
    "table.field_names = scores_headers\n",
    "table.add_rows(scores_list)\n",
    "print(table)"
   ],
   "id": "57053a645b552105",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------+\n",
      "|   Error Scores with Default Params   |\n",
      "+------+----------+--------------------+\n",
      "| Fold | R2 Score | Mean Squared Error |\n",
      "+------+----------+--------------------+\n",
      "|  1   |   0.45   |      2307.94       |\n",
      "|  2   |  -0.24   |      5851.16       |\n",
      "|  3   |   0.60   |      2747.84       |\n",
      "|  4   |   0.74   |      1587.71       |\n",
      "|  5   |   0.64   |      1807.87       |\n",
      "|  6   |   0.70   |      2304.31       |\n",
      "|  7   |   0.50   |      2074.93       |\n",
      "|  8   |   0.38   |      3719.86       |\n",
      "|  9   |   0.33   |      7637.25       |\n",
      "|  10  |   0.33   |      5687.03       |\n",
      "+------+----------+--------------------+\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
